## 项目准备
1. 安装mysql， host `127.0.0.1` port `3306`
2. 创建用户 `root` 密码 `123456` (以上4项均可在配置文件修改)
3. 创建空数据库`crawler_eastmoney`
4. 修改配置文件`./src/config/global.yaml`
5. 加载配置项`requirements.txt`
## 项目结构
1. 分两个文件作为入口,从src中启动项目
   1. `start_get_data.py` 获取数据并存到数据库
   2. `start_process_data.py` 从数据库获取数据并处理数据
2. config文件夹存储配置文件
   1. 使用yaml格式存储数据
   2. `config.py` 创建Config类从配置文件获取配置
   3. `global.yaml` 配置文件
      1. api相关配置，可以通过修改获取页数和每页数量来确定获取的基金产品总数
      2. 数据库相关配置，可以更改用户或者数据库
3. `spider.py`
   1. `Http`类：http相关的方法，get请求增加了重试
   2. `time_limit`：限频的装饰器
   3. 获取基金产品列表
   4. 获取基金历史净值
4. `mysql.py`
   1. `SQL`类：数据库相关的公共方法
   2. `FundSQL`类：继承SQL类，基金净值相关具体实现的私有方法
   3. `lock_sql`：数据库锁的装饰器
5. `tools.py`
   1. 自动创建目录方法
   2. `result`,`result/month`,`data`,`download`
6. `start_process_data.py`
   1. 单文件完成所有数据处理
   2. 先分local和mysql两种模式获取全量数据并存到`data`文件夹，返回dataframe格式数据
   3. 处理dataframe数据，先初始化所有的列，并获取所有后续需要使用的数据
      1. 聚合月数据，算出月收益
      2. 聚合年数据，算出年收益、年夏普、年最大回撤
      3. 使用全量数据，算出总收益，年化收益，总夏普，总最大回撤
   4. 储存数据到csv文件
## 生成目录结构
1. `result`：结果目录，包括fund总表和所有月数据表，和月数据文件夹
2. `result/month`：结果目录，包括所有月数据
3. `data`：从数据库获取数据并导出的全量数据文件夹
4. `download`：替代数据库的本地数据获取文件夹
## 项目实现原则
1. 数据获取和数据处理分离
2. 实现过程单元化，语义化，模块化
3. 在主函数中能获取整体项目逻辑
4. 公共方法和私有方法分开
5. 具体方法之外的拓展使用装饰器
6. 可能变动的内容放在配置文件里
   
## 项目环境
1. python 3.10
2. pandas 1.5.3(sqlalchemy 2.0.0与pandas早期版本不兼容，需要更新pandas到1.5.3)
